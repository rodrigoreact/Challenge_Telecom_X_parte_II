# -*- coding: utf-8 -*-
"""Telecom_x_2_parte_10_08_2025.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OlbNIfxZ57brggYqHbpioOZ610UeNiU3
"""

import pandas as pd
ruta = '/content/sample_data/df_sin_customerID.csv'
df = pd.read_csv(ruta)
print(df.head())

unique_counts = df.nunique()
print(unique_counts)

cat_cols = df.select_dtypes(include=['object']).columns

for col in cat_cols:
    print(f"Opciones en la columna '{col}':")
    print(df[col].unique())
    print("-" * 40)

df['customer.gender'] = df['customer.gender'].replace({
    'Female': 0,
    'Male': 1
})

print(df['customer.gender'].value_counts())
print(df['customer.gender'].dtype)

cols_binarias = [
    'Churn',
    'customer.Partner',
    'customer.Dependents',
    'phone.PhoneService',
    'account.PaperlessBilling'
]

for col in cols_binarias:
    if col in df.columns:
        df[col] = df[col].replace({'Yes': 1, 'No': 0})

# Verifica que qued√≥ bien:
for col in cols_binarias:
    if col in df.columns:
        print(f"Valores √∫nicos en {col}: {df[col].unique()}")

# Mapeos para columnas con 'Yes', 'No', y una tercera categor√≠a especial
cols_3vals_map_012 = [
    'phone.MultipleLines',
    'internet.OnlineSecurity',
    'internet.OnlineBackup',
    'internet.DeviceProtection',
    'internet.TechSupport',
    'internet.StreamingTV',
    'internet.StreamingMovies'
]

for col in cols_3vals_map_012:
    if col in df.columns:
        if col == 'phone.MultipleLines':
            df[col] = df[col].replace({'No': 0, 'Yes': 1, 'No phone service': 2})
        else:
            df[col] = df[col].replace({'No': 0, 'Yes': 1, 'No internet service': 2})

# Para 'internet.InternetService' tambi√©n One-Hot Encoding
if 'internet.InternetService' in df.columns:
    dummies = pd.get_dummies(df['internet.InternetService'], prefix='internet.InternetService')
    df = pd.concat([df.drop('internet.InternetService', axis=1), dummies], axis=1)

# Para 'account.Contract' One-Hot Encoding
if 'account.Contract' in df.columns:
    dummies = pd.get_dummies(df['account.Contract'], prefix='account.Contract')
    df = pd.concat([df.drop('account.Contract', axis=1), dummies], axis=1)

# Verificaci√≥n r√°pida:
print(df.head())
print(df.dtypes[df.dtypes == 'object'])  # no deber√≠an quedar columnas object relacionadas a estas

df[col] = df[col].replace({'No': 0, 'Yes': 1, 'No phone service': 2}).astype(int)

df[col] = df[col].replace({'No': 0, 'Yes': 1, 'No internet service': 2}).astype(int)

# Mostrar las primeras filas del DataFrame completo con todas las columnas
print(df.head())

# Opcional: para ver la lista completa de columnas transformadas
print("Columnas del DataFrame:")
print(df.columns.tolist())

# Si quieres un resumen m√°s ordenado de tipos y valores √∫nicos:
for col in df.columns:
    print(f"{col}: dtype={df[col].dtype}, valores √∫nicos={df[col].nunique()}")

if 'account.PaymentMethod' in df.columns:
    dummies = pd.get_dummies(df['account.PaymentMethod'], prefix='account.PaymentMethod')
    df = pd.concat([df.drop('account.PaymentMethod', axis=1), dummies], axis=1)

bool_cols = df.select_dtypes(include='bool').columns
df[bool_cols] = df[bool_cols].astype(int)

# Aplicar one-hot encoding a 'account.PaymentMethod'
if 'account.PaymentMethod' in df.columns:
    dummies = pd.get_dummies(df['account.PaymentMethod'], prefix='account.PaymentMethod')
    df = pd.concat([df.drop('account.PaymentMethod', axis=1), dummies], axis=1)

# Convertir booleanos a enteros
bool_cols = df.select_dtypes(include='bool').columns
df[bool_cols] = df[bool_cols].astype(int)

# Mostrar primeras filas y tipos de dato
print(df.head())
print("\nTipos de datos en el DataFrame:")
print(df.dtypes)

import pandas as pd

# --- Suponiendo que ya tienes cargado tu DataFrame df ---

# 1. Convertir columnas binarias Yes/No a 0/1
cols_binarias = [
    'Churn',
    'customer.gender',
    'customer.Partner',
    'customer.Dependents',
    'phone.PhoneService',
    'account.PaperlessBilling'
]

for col in cols_binarias:
    if col in df.columns:
        df[col] = df[col].replace({'Yes': 1, 'No': 0, 'Female': 0, 'Male': 1})

# 2. Convertir columnas con 3 valores a 0/1/2
cols_3vals_map_012 = [
    'phone.MultipleLines',
    'internet.OnlineSecurity',
    'internet.OnlineBackup',
    'internet.DeviceProtection',
    'internet.TechSupport',
    'internet.StreamingTV',
    'internet.StreamingMovies'
]

for col in cols_3vals_map_012:
    if col in df.columns:
        if col == 'phone.MultipleLines':
            df[col] = df[col].replace({'No': 0, 'Yes': 1, 'No phone service': 2}).astype(int)
        else:
            df[col] = df[col].replace({'No': 0, 'Yes': 1, 'No internet service': 2}).astype(int)

# 3. One-hot encoding para 'internet.InternetService'
if 'internet.InternetService' in df.columns:
    dummies = pd.get_dummies(df['internet.InternetService'], prefix='internet.InternetService')
    df = pd.concat([df.drop('internet.InternetService', axis=1), dummies], axis=1)

# 4. One-hot encoding para 'account.Contract'
if 'account.Contract' in df.columns:
    dummies = pd.get_dummies(df['account.Contract'], prefix='account.Contract')
    df = pd.concat([df.drop('account.Contract', axis=1), dummies], axis=1)

# 5. One-hot encoding para 'account.PaymentMethod'
if 'account.PaymentMethod' in df.columns:
    dummies = pd.get_dummies(df['account.PaymentMethod'], prefix='account.PaymentMethod')
    df = pd.concat([df.drop('account.PaymentMethod', axis=1), dummies], axis=1)

# 6. Convertir booleanos a enteros para evitar True/False
bool_cols = df.select_dtypes(include='bool').columns
df[bool_cols] = df[bool_cols].astype(int)

# 7. Mostrar primeras filas y tipos para verificar
print(df.head())
print("\nTipos de datos en el DataFrame:")
print(df.dtypes)

# 8. Guardar DataFrame limpio en CSV
df.to_csv("df_transformado.csv", index=False, encoding="utf-8-sig")
print("\nArchivo df_transformado.csv guardado correctamente.")

# Ver proporci√≥n de valores √∫nicos en la columna 'Churn'
print("Distribuci√≥n de la variable Churn:")
print(df['Churn'].value_counts())

print("\nProporci√≥n relativa (porcentaje) de cada clase:")
print(df['Churn'].value_counts(normalize=True) * 100)

"""Esto nos muestra:
Cu√°ntos clientes cancelaron (Churn = 1) y cu√°ntos no (Churn = 0).
El porcentaje de cada clase en el dataset para entender si hay desbalance.
"""

# Ver cu√°ntos valores NaN hay en cada columna
print(df.isna().sum())

from sklearn.impute import SimpleImputer
from imblearn.over_sampling import SMOTE
import pandas as pd

# Imputar valores faltantes con la media en columnas num√©ricas
imputer = SimpleImputer(strategy='mean')

# Separar caracter√≠sticas y etiqueta
X = df.drop('Churn', axis=1)
y = df['Churn']

# Imputar solo en columnas num√©ricas, pero para evitar problemas con dummies (bool), vamos a imputar todo
X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)

# Ahora aplicar SMOTE
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X_imputed, y)

print("Distribuci√≥n original de Churn:")
print(y.value_counts())

print("\nDistribuci√≥n despu√©s de aplicar SMOTE:")
print(y_res.value_counts())

# Crear nuevo dataframe balanceado
df_resampled = X_res.copy()
df_resampled['Churn'] = y_res

"""¬°Perfecto! Ahora el dataset est√° balanceado: tienen igual cantidad de clientes que no cancelaron (0) y que s√≠ cancelaron (1), ambos con 5174 registros.

Esto es muy √∫til para entrenar modelos que no se sesguen hacia la clase mayoritaria.

En este contexto, "churn" generalmente significa que el cliente cancel√≥ o se fue (es decir, abandon√≥ el servicio).

Churn = 1 ‚Üí El cliente s√≠ cancel√≥ el servicio (evadi√≥ o dej√≥ de usarlo).

Churn = 0 ‚Üí El cliente no cancel√≥ (se mantuvo activo).

Si en tu dataset o negocio usas "churn" con otro significado, ser√≠a bueno aclararlo, pero por convenci√≥n "churn" es abandono o p√©rdida de cliente.
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Supongamos que tu dataframe balanceado se llama df_resampled
# Para correlaci√≥n, s√≥lo consideramos variables num√©ricas
corr_matrix = df_resampled.corr()

# Mostrar matriz de correlaci√≥n
print(corr_matrix)

# Visualizar la matriz con un mapa de calor
plt.figure(figsize=(12,10))
sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap="coolwarm", cbar=True)
plt.title("Matriz de correlaci√≥n")
plt.show()

"""Interpretaci√≥n r√°pida:

Valores cercanos a +1 o -1 indican alta correlaci√≥n positiva o negativa.
Valores cerca de 0 indican poca o ninguna correlaci√≥n.
Puedes identificar variables muy correlacionadas entre s√≠ (posible multicolinealidad).

Observar qu√© variables tienen mayor correlaci√≥n con Churn (variable objetivo).
"""

# Correlaci√≥n absoluta con Churn, ordenada de mayor a menor
corr_with_target = corr_matrix['Churn'].abs().sort_values(ascending=False)

print("Correlaci√≥n absoluta de variables con Churn:")
print(corr_with_target)

# Fijar un umbral m√≠nimo para seleccionar variables importantes
umbral = 0.1  # Puedes ajustar seg√∫n necesidad

variables_relevantes = corr_with_target[corr_with_target > umbral].index.tolist()

print("\nVariables seleccionadas (correlaci√≥n > {}):".format(umbral))
print(variables_relevantes)

# Crear nuevo dataframe solo con variables seleccionadas (incluyendo Churn)
df_seleccionado = df_resampled[variables_relevantes]

print("\nDataframe reducido con variables seleccionadas:")
print(df_seleccionado.head())

variables = ['Churn', 'account.Contract_Month-to-month', 'customer.tenure', 'internet.OnlineSecurity', 'internet.TechSupport', 'account.Contract_Two year', 'internet.InternetService_Fiber optic', 'internet.OnlineBackup', 'account.PaymentMethod_Electronic check', 'internet.DeviceProtection', 'internet.InternetService_No', 'internet.StreamingMovies', 'internet.StreamingTV', 'account.PaperlessBilling', 'account.Charges.Monthly', 'Cuentas_Diarias', 'account.Charges.Total', 'account.Contract_One year', 'customer.Dependents', 'customer.Partner', 'account.PaymentMethod_Credit card (automatic)', 'customer.SeniorCitizen', 'account.PaymentMethod_Bank transfer (automatic)', 'internet.InternetService_DSL', 'account.PaymentMethod_Mailed check']

print("N√∫mero total de variables seleccionadas:", len(variables))

import numpy as np

# Subconjunto con las variables relevantes (sin incluir 'Churn' porque es la variable objetivo)
vars_sin_churn = [v for v in variables if v != 'Churn']

# Matriz de correlaci√≥n para esas variables
corr_sub = df_resampled[vars_sin_churn].corr().abs()

# M√°scara para la parte superior de la matriz (sin diagonal)
upper_tri = corr_sub.where(np.triu(np.ones(corr_sub.shape), k=1).astype(bool))

# Encuentra pares con correlaci√≥n mayor a 0.8
alta_corr = [(col, row, corr_sub.loc[row, col])
             for col in upper_tri.columns
             for row in upper_tri.index
             if upper_tri.loc[row, col] > 0.8]

if alta_corr:
    print("Pares de variables con correlaci√≥n mayor a 0.8:")
    for col1, col2, corr_val in alta_corr:
        print(f"{col1} y {col2}: correlaci√≥n = {corr_val:.2f}")
else:
    print("No se encontraron pares con correlaci√≥n mayor a 0.8.")

"""1. Variables altamente correlacionadas:
internet.InternetService_No tiene correlaci√≥n alta (>0.8) con varias variables de servicios de internet:

internet.OnlineSecurity (0.85)

internet.TechSupport (0.84)

internet.OnlineBackup (0.81)

internet.DeviceProtection (0.81)

Interpretaci√≥n:
Estas variables probablemente indican que cuando no tienes servicio de internet (InternetService_No=1), entonces no tienes ninguno de esos servicios extra, por eso la alta correlaci√≥n. Son en la pr√°ctica redundantes.

2. Relaci√≥n entre cargos y servicios de internet:
account.Charges.Monthly y internet.InternetService_Fiber optic: 0.81

Cuentas_Diarias y internet.InternetService_Fiber optic: 0.81

Cuentas_Diarias y account.Charges.Monthly: 1.00 (correlaci√≥n perfecta)

Interpretaci√≥n:
Los cargos mensuales y las cuentas diarias est√°n muy relacionados con tener fibra √≥ptica, lo que tiene sentido: fibra suele ser un servicio m√°s caro.

Adem√°s, Cuentas_Diarias es un c√°lculo derivado de account.Charges.Monthly (probablemente), por eso tienen correlaci√≥n perfecta.

3. Correlaci√≥n entre total facturado y tiempo de cliente:
account.Charges.Total y customer.tenure: 0.86

Interpretaci√≥n:
Total facturado (Charges.Total) se acumula en el tiempo (tenure). Esto es l√≥gico: mientras m√°s tiempo lleva un cliente, m√°s ha pagado.

¬øQu√© puedes hacer?
Eliminar o combinar variables redundantes:

Dado que internet.InternetService_No indica ausencia total de internet, y las otras columnas OnlineSecurity, TechSupport, etc., son casi redundantes para clientes sin servicio, podr√≠as:

Mantener solo internet.InternetService_No y eliminar esas otras variables, o

Mantener las otras variables y eliminar internet.InternetService_No (m√°s detallado).

Eliminar una de las variables perfectamente correlacionadas:

Cuentas_Diarias y account.Charges.Monthly son redundantes. Puedes eliminar una (por ejemplo, Cuentas_Diarias) para evitar multicolinealidad.

Cuidado con la correlaci√≥n entre account.Charges.Total y customer.tenure:

Como est√°n muy correlacionadas, puede que ambas aporten informaci√≥n similar. Puedes probar modelos con ambas, o eliminar una.
"""

cols_a_eliminar = ['internet.OnlineSecurity', 'internet.TechSupport', 'Cuentas_Diarias']

df = df.drop(columns=cols_a_eliminar)

print("Columnas eliminadas:", cols_a_eliminar)
print("Columnas actuales:")
print(df.columns)

# Mostrar total de columnas
print("Total columnas actuales:", len(df.columns))

# Mostrar total de columnas
print("Total columnas actuales:", len(df.columns))

# Guardar copia actualizada en CSV
df.to_csv("df_actualizado_sin_columnas.csv", index=False, encoding="utf-8-sig")

df = df.drop(columns=['customer.tenure'])

print("Columna 'customer.tenure' eliminada.")
print("Columnas actuales:")
print(df.columns)

print(df.columns.tolist())

for col in df.columns:
    print(col)

print("Total de columnas:", len(df.columns))

# Variable dependiente
y = df['Churn']

# Variables independientes
X = df.drop(columns=['Churn'])

print(f"Variables independientes: {X.shape[1]} columnas")
print(f"Variable dependiente: {y.name}")

import matplotlib.pyplot as plt
import seaborn as sns

# Si 'account.Contract' est√° codificada en one-hot, quiz√°s prefieras usar la original o crear una variable categ√≥rica para graficar

# 1. Gr√°fico de barras: Proporci√≥n de Churn por tipo de contrato
plt.figure(figsize=(8,5))
sns.countplot(data=df, x='account.Contract', hue='Churn')
plt.title('Cancelaci√≥n (Churn) por Tipo de Contrato')
plt.ylabel('N√∫mero de clientes')
plt.xlabel('Tipo de Contrato')
plt.legend(title='Churn', labels=['No', 'S√≠'])
plt.show()

# 2. Boxplot: Distribuci√≥n del tiempo de permanencia (tenure) seg√∫n Churn
plt.figure(figsize=(8,5))
sns.boxplot(data=df, x='Churn', y='customer.tenure')
plt.title('Distribuci√≥n del Tiempo de Permanencia seg√∫n Cancelaci√≥n')
plt.xlabel('Churn (0=No, 1=S√≠)')
plt.ylabel('Tiempo de Permanencia (Meses)')
plt.show()

# Crear la columna original a partir de las columnas one-hot
def reconstruir_contrato(row):
    if row['account.Contract_Month-to-month'] == 1:
        return 'Month-to-month'
    elif row['account.Contract_One year'] == 1:
        return 'One year'
    elif row['account.Contract_Two year'] == 1:
        return 'Two year'
    else:
        return 'Unknown'

df['account.Contract'] = df.apply(reconstruir_contrato, axis=1)

# Ahora graficamos
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(8,5))
sns.countplot(data=df, x='account.Contract', hue='Churn')
plt.title('Cancelaci√≥n (Churn) por Tipo de Contrato')
plt.ylabel('N√∫mero de clientes')
plt.xlabel('Tipo de Contrato')
plt.legend(title='Churn', labels=['No', 'S√≠'])
plt.show()

plt.figure(figsize=(6,4))
sns.countplot(data=df, x='customer.gender', hue='Churn')
plt.title('Cancelaci√≥n seg√∫n G√©nero')
plt.ylabel('N√∫mero de clientes')
plt.xlabel('G√©nero')
plt.legend(title='Churn', labels=['No', 'S√≠'])
plt.show()

plt.figure(figsize=(6,4))
sns.countplot(data=df, x='customer.SeniorCitizen', hue='Churn')
plt.title('Cancelaci√≥n seg√∫n Senior Citizen (0=No, 1=S√≠)')
plt.ylabel('N√∫mero de clientes')
plt.xlabel('Senior Citizen')
plt.legend(title='Churn', labels=['No', 'S√≠'])
plt.show()

plt.figure(figsize=(8,4))
sns.countplot(data=df, x='phone.MultipleLines', hue='Churn')
plt.title('Cancelaci√≥n seg√∫n M√∫ltiples L√≠neas Telef√≥nicas')
plt.ylabel('N√∫mero de clientes')
plt.xlabel('M√∫ltiples L√≠neas')
plt.legend(title='Churn', labels=['No', 'S√≠'])
plt.show()

plt.figure(figsize=(8,4))
sns.countplot(data=df, x='internet.InternetService', hue='Churn')
plt.title('Cancelaci√≥n seg√∫n Tipo de Servicio de Internet')
plt.ylabel('N√∫mero de clientes')
plt.xlabel('Servicio de Internet')
plt.legend(title='Churn', labels=['No', 'S√≠'])
plt.show()

# Crear columna categ√≥rica basada en las columnas dummy
def obtener_servicio(row):
    if row['internet.InternetService_DSL'] == 1:
        return 'DSL'
    elif row['internet.InternetService_Fiber optic'] == 1:
        return 'Fiber optic'
    elif row['internet.InternetService_No'] == 1:
        return 'No'
    else:
        return 'Unknown'

df['InternetService_cat'] = df.apply(obtener_servicio, axis=1)

# Ahora graficar con esa columna temporal
plt.figure(figsize=(8,4))
sns.countplot(data=df, x='InternetService_cat', hue='Churn')
plt.title('Cancelaci√≥n seg√∫n Tipo de Servicio de Internet')
plt.ylabel('N√∫mero de clientes')
plt.xlabel('Servicio de Internet')
plt.show()

print("N√∫mero de columnas antes:", len(df.columns))

# Crear la columna temporal para la gr√°fica
def obtener_servicio(row):
    if row['internet.InternetService_DSL'] == 1:
        return 'DSL'
    elif row['internet.InternetService_Fiber optic'] == 1:
        return 'Fiber optic'
    elif row['internet.InternetService_No'] == 1:
        return 'No'
    else:
        return 'Unknown'

df['InternetService_cat'] = df.apply(obtener_servicio, axis=1)

print("N√∫mero de columnas despu√©s:", len(df.columns))

df.to_csv("df_normalizado_ultimo.csv", index=False, encoding="utf-8-sig")

"""Prepare el c√≥digo para que se puedas elegir f√°cilmente entre normalizaci√≥n y estandarizaci√≥n. Columnas de: cargos, edad, tenure, genero.
Vamos a aclarar:

Cargos: son num√©ricos continuos (account.Charges.Monthly, account.Charges.Total, Cuentas_Diarias), s√≠ se normalizan o estandarizan.

Edad (o similar): en tu caso tienes customer.SeniorCitizen que es binaria (0 o 1), y customer.tenure que es num√©rica (meses que lleva como cliente).

G√©nero: ya la convertiste en binaria (0 y 1), no hace falta normalizar ni estandarizar.
"""

from sklearn.preprocessing import MinMaxScaler, StandardScaler

# Columnas num√©ricas continuas (cargos y tenure)
columnas_numericas = ['account.Charges.Monthly', 'account.Charges.Total', 'Cuentas_Diarias', 'customer.tenure']

# Normalizaci√≥n (Min-Max Scaling)
scaler_minmax = MinMaxScaler()
df[columnas_numericas] = scaler_minmax.fit_transform(df[columnas_numericas])

# --- Opci√≥n: Estandarizaci√≥n (Z-score) ---
# scaler_standard = StandardScaler()
# df[columnas_numericas] = scaler_standard.fit_transform(df[columnas_numericas])

print(df[columnas_numericas].head())

"""Claro, veamos qu√© nos dice esa normalizaci√≥n y qu√© conclusiones preliminares podemos sacar:

¬øQu√© es la normalizaci√≥n Min-Max?
Convierte los valores originales de las columnas a un rango entre 0 y 1, respetando las proporciones relativas. Esto ayuda a que las variables con diferentes escalas sean comparables para ciertos modelos o an√°lisis.

Interpretaci√≥n de las variables normalizadas:

account.Charges.Monthly, account.Charges.Total y Cuentas_Diarias:
Valores cercanos a 0 indican clientes con cargos mensuales y totales bajos (o pocas cuentas diarias), mientras que valores cercanos a 1 indican clientes con cargos altos o muchas cuentas diarias.

customer.tenure:
Muestra cu√°nto tiempo lleva el cliente con el servicio. Un valor bajo (cercano a 0) indica clientes nuevos; uno alto (cercano a 1) clientes antiguos.

¬øQu√© se puede concluir?

Los valores normalizados permiten analizar con mayor facilidad la influencia relativa de estas variables en el modelo o en visualizaciones.

Por ejemplo, puedes correlacionar la duraci√≥n del cliente (tenure) con la probabilidad de cancelaci√≥n (Churn) y ver si los clientes nuevos tienden a cancelar m√°s que los antiguos.

Los cargos (mensuales, totales) normalizados facilitan comparaciones entre clientes para detectar patrones o segmentos de riesgo.

Adem√°s, al tener todas las variables en la misma escala, los modelos que dependen de distancias (como KNN o SVM) funcionar√°n mejor.

Pr√≥ximos pasos recomendados:

Explorar visualmente estas variables junto con la variable objetivo (Churn) para detectar patrones.

Usar estas variables normalizadas para entrenar modelos de clasificaci√≥n.

Analizar la importancia de estas variables y si contribuyen significativamente al modelo.
"""

df = df  # aqu√≠ ir√≠a alguna transformaci√≥n si quieres
df.to_csv('df_normalizado_037horas.csv', index=False, encoding='utf-8-sig')

df.to_csv('df_normalizado.csv', index=False, encoding='utf-8-sig')
from google.colab import files
files.download('df_normalizado_037horas.csv')

"""Separaci√≥n de Datos
Usaremos train_test_split de scikit-learn.
Aqu√≠ puedes elegir la proporci√≥n (por ejemplo, 80% para entrenamiento y 20% para prueba).
"""

from sklearn.model_selection import train_test_split

# Supongamos que tus datos est√°n en un DataFrame df
# X = variables predictoras
# y = Churn

X = df.drop('Churn', axis=1)  # Reemplaza 'precio' por el nombre de tu variable objetivo
y = df['Churn']

# Separaci√≥n en entrenamiento y prueba (80/20)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print("Tama√±o entrenamiento:", X_train.shape)
print("Tama√±o prueba:", X_test.shape)

"""Lo que tienes:

Tama√±o entrenamiento (5634, 20) ‚Üí 5 634 registros (filas) y 20 variables (columnas) que usar√°s para ajustar el modelo (aprender patrones).

Tama√±o prueba (1409, 20) ‚Üí 1 409 registros y 20 variables que usar√°s para evaluar el modelo en datos que no ha visto antes.

Como ya tenemos nuestros datos separados en entrenamiento y prueba, podemos comenzar con un primer modelo de Regresi√≥n Lineal y luego iremos comparando con otros.
"""

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

# Crear el modelo
modelo_rl = LinearRegression()

# Entrenar el modelo
modelo_rl.fit(X_train, y_train)

# Hacer predicciones
y_pred_rl = modelo_rl.predict(X_test)

# Evaluar el modelo
mse = mean_squared_error(y_test, y_pred_rl)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred_rl)

print("Resultados Regresi√≥n Lineal:")
print(f"  MSE: {mse:.2f}")
print(f"  RMSE: {rmse:.2f}")
print(f"  R¬≤: {r2:.4f}")

"""Ese ValueError normalmente aparece porque las dimensiones o tipos de datos de X_train y y_train no son las que scikit-learn espera.

En un modelo de regresi√≥n lineal (modelo_rl.fit(X_train, y_train)), lo usual es que:

X_train sea un array o DataFrame con forma (n_muestras, n_caracter√≠sticas)

y_train sea un array o Serie con forma (n_muestras,) (o (n_muestras, 1) en algunos casos)

Los errores m√°s comunes que provocan este mensaje son:

Valores no num√©ricos en X_train o y_train (strings, NaN, None).

Dimensiones incorrectas (por ejemplo, X_train como un vector en lugar de una matriz 2D).

Longitudes distintas entre X_train y y_train.
"""

print(X_train.shape)
print(y_train.shape)
print(X_train.dtypes)
print(y_train.dtypes)

"""este es el problema: casi la mitad de tus columnas (object) son categ√≥ricas, y la regresi√≥n lineal de scikit-learn no puede entrenar con strings directamente.

Antes de ajustar el modelo, necesitamos codificar estas variables categ√≥ricas (por ejemplo con One-Hot Encoding o Label Encoding).
"""

from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression

# 1. Identificar columnas categ√≥ricas y num√©ricas
cat_cols = X_train.select_dtypes(include=['object']).columns
num_cols = X_train.select_dtypes(exclude=['object']).columns

# 2. Preprocesador: One-Hot para categ√≥ricas, pasar num√©ricas tal cual
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(drop='first'), cat_cols),
        ('num', 'passthrough', num_cols)
    ]
)

# 3. Crear pipeline con regresi√≥n lineal
modelo_rl = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('regressor', LinearRegression())
])

# 4. Entrenar
modelo_rl.fit(X_train, y_train)

# 5. Predecir
y_pred = modelo_rl.predict(X_test)

"""Entonces ahora el error no es por las variables categ√≥ricas, sino porque a√∫n tienes valores NaN en tu X_train o X_test.

La forma m√°s segura de manejarlo antes de modelar es a√±adir un imputador dentro del pipeline para reemplazar los NaN.
"""

from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression

# 1. Identificar columnas categ√≥ricas y num√©ricas
cat_cols = X_train.select_dtypes(include=['object']).columns
num_cols = X_train.select_dtypes(exclude=['object']).columns

# 2. Pipelines de preprocesamiento para cada tipo
cat_pipeline = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('encoder', OneHotEncoder(drop='first'))
])

num_pipeline = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median'))
])

# 3. Combinar en un ColumnTransformer
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', cat_pipeline, cat_cols),
        ('num', num_pipeline, num_cols)
    ]
)

# 4. Crear pipeline final con regresi√≥n lineal
modelo_rl = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('regressor', LinearRegression())
])

# 5. Entrenar
modelo_rl.fit(X_train, y_train)

# 6. Predecir
y_pred = modelo_rl.predict(X_test)

"""Ahora el problema es que tu variable objetivo y_train (Churn) est√° en formato texto ('No' y 'Yes') y el modelo espera n√∫meros (0 y 1)."""

# Convertir la variable objetivo a 0 y 1
y_train = y_train.map({'No': 0, 'Yes': 1})
y_test = y_test.map({'No': 0, 'Yes': 1})

from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import numpy as np
import matplotlib.pyplot as plt

# 1. Crear y entrenar el modelo
modelo_lr = LinearRegression()
modelo_lr.fit(X_train, y_train)

# 2. Hacer predicciones
y_pred = modelo_lr.predict(X_test)

# 3. Calcular m√©tricas
r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))

print("Resultados Regresi√≥n Lineal")
print("----------------------------")
print(f"R¬≤: {r2:.4f}")
print(f"MAE: {mae:.4f}")
print(f"RMSE: {rmse:.4f}")

# 4. Gr√°fico de valores reales vs. predichos
plt.scatter(y_test, y_pred, alpha=0.5, color="blue")
plt.xlabel("Valores reales")
plt.ylabel("Valores predichos")
plt.title("Regresi√≥n Lineal - Real vs. Predicho")
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.show()

print(X_train.select_dtypes(include=['object']).columns)

# Lista columnas binarias a mapear a 0/1
binarias = ['customer.gender', 'customer.Partner', 'customer.Dependents',
            'phone.PhoneService', 'account.PaperlessBilling']

# Mapear Yes/No o Male/Female a 0/1
mapping_binario = {
    'Yes': 1,
    'No': 0,
    'Male': 1,
    'Female': 0
}

for col in binarias:
    X_train[col] = X_train[col].map(mapping_binario)
    X_test[col] = X_test[col].map(mapping_binario)

# Columnas con m√°s de dos categor√≠as (one-hot encoding)
multicat = ['phone.MultipleLines', 'internet.InternetService', 'internet.OnlineSecurity',
            'internet.OnlineBackup', 'internet.DeviceProtection', 'internet.TechSupport',
            'internet.StreamingTV', 'internet.StreamingMovies', 'account.Contract',
            'account.PaymentMethod']

X_train = pd.get_dummies(X_train, columns=multicat, drop_first=True)
X_test = pd.get_dummies(X_test, columns=multicat, drop_first=True)

# Alinear columnas para evitar problemas con columnas faltantes
X_test = X_test.reindex(columns = X_train.columns, fill_value=0)

from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import numpy as np
import matplotlib.pyplot as plt

# 1. Crear y entrenar el modelo
modelo_lr = LinearRegression()
modelo_lr.fit(X_train, y_train)

# 2. Hacer predicciones
y_pred = modelo_lr.predict(X_test)

# 3. Calcular m√©tricas
r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))

print("Resultados Regresi√≥n Lineal")
print("----------------------------")
print(f"R¬≤: {r2:.4f}")
print(f"MAE: {mae:.4f}")
print(f"RMSE: {rmse:.4f}")

# 4. Gr√°fico de valores reales vs. predichos
plt.scatter(y_test, y_pred, alpha=0.5, color="blue")
plt.xlabel("Valores reales")
plt.ylabel("Valores predichos")
plt.title("Regresi√≥n Lineal - Real vs. Predicho")
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.show()

print(X_train.isna().sum())

from sklearn.impute import SimpleImputer

imputer = SimpleImputer(strategy='mean')
df[['account.Charges.Total']] = imputer.fit_transform(df[['account.Charges.Total']])

# Ejecutas imputaci√≥n aqu√≠
print(df['account.Charges.Total'].isnull().sum())  # Despu√©s deber√≠a mostrar 0

from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import numpy as np
import matplotlib.pyplot as plt

# 1. Crear y entrenar el modelo
modelo_lr = LinearRegression()
modelo_lr.fit(X_train, y_train)

# 2. Hacer predicciones
y_pred = modelo_lr.predict(X_test)

# 3. Calcular m√©tricas
r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))

print("Resultados Regresi√≥n Lineal")
print("----------------------------")
print(f"R¬≤: {r2:.4f}")
print(f"MAE: {mae:.4f}")
print(f"RMSE: {rmse:.4f}")

# 4. Gr√°fico de valores reales vs. predichos
plt.scatter(y_test, y_pred, alpha=0.5, color="blue")
plt.xlabel("Valores reales")
plt.ylabel("Valores predichos")
plt.title("Regresi√≥n Lineal - Real vs. Predicho")
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.show()

# Verificar si hay NaN en alguna columna del conjunto de entrenamiento
print(X_train.isna().sum())

# Imputar NaN en todas las columnas num√©ricas con la media (o mediana si prefieres)
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy='mean')
X_train_imputed = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)
X_test_imputed = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)

# Verificar que ya no haya NaN
print(X_train_imputed.isna().sum())

df['account.Charges.Total'].fillna(df['account.Charges.Total'].median(), inplace=True)

df['account.Charges.Total'] = df['account.Charges.Total'].fillna(df['account.Charges.Total'].median())

# Verificar si quedan NaN en toda la columna
print(df['account.Charges.Total'].isna().sum())

# O para todas las columnas num√©ricas (o todo el df)
print(df.isna().sum())

# Reemplazar valores NaN en 'account.Charges.Total' por la mediana y guardar en df
df['account.Charges.Total'] = df['account.Charges.Total'].fillna(df['account.Charges.Total'].median())

# Puedes verificar nuevamente que ya no hay NaN
print(df['account.Charges.Total'].isna().sum())

from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import numpy as np
import matplotlib.pyplot as plt

# 1. Crear y entrenar el modelo
modelo_lr = LinearRegression()
modelo_lr.fit(X_train, y_train)

# 2. Hacer predicciones
y_pred = modelo_lr.predict(X_test)

# 3. Calcular m√©tricas
r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))

print("Resultados Regresi√≥n Lineal")
print("----------------------------")
print(f"R¬≤: {r2:.4f}")
print(f"MAE: {mae:.4f}")
print(f"RMSE: {rmse:.4f}")

# 4. Gr√°fico de valores reales vs. predichos
plt.scatter(y_test, y_pred, alpha=0.5, color="blue")
plt.xlabel("Valores reales")
plt.ylabel("Valores predichos")
plt.title("Regresi√≥n Lineal - Real vs. Predicho")
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.show()

print(X_train.isnull().sum())

# Detectar columnas duplicadas
duplicated_cols = df.columns[df.columns.duplicated()].unique()
print("Columnas duplicadas:", duplicated_cols.tolist())

# Eliminar columnas duplicadas (excepto la primera)
df = df.loc[:, ~df.columns.duplicated()]

# Verificar si hay NaN en la columna problematica
print("NaN en 'account.Charges.Total' antes de fillna:", df['account.Charges.Total'].isna().sum())

# Rellenar NaN con la mediana
df['account.Charges.Total'] = df['account.Charges.Total'].fillna(df['account.Charges.Total'].median())

# Verificar que no queden NaN
print("NaN en 'account.Charges.Total' despu√©s de fillna:", df['account.Charges.Total'].isna().sum())

# Mostrar cu√°ntos NaN hay en todas las columnas
print(df.isna().sum())

# Mostrar los tipos de datos para detectar columnas no num√©ricas
print(df.dtypes)

# Convertir 'Churn' a 0/1
df['Churn'] = df['Churn'].map({'No': 0, 'Yes': 1})

# Variables binarias con valores 'Yes'/'No'
bin_cols = ['customer.gender', 'customer.Partner', 'customer.Dependents',
            'phone.PhoneService', 'account.PaperlessBilling']

for col in bin_cols:
    df[col] = df[col].map({'Yes': 1, 'No': 0, 'Male': 1, 'Female': 0})

# Variables con m√°s de 2 categor√≠as (one-hot encoding)
multi_cat_cols = ['phone.MultipleLines', 'internet.InternetService', 'internet.OnlineSecurity',
                  'internet.OnlineBackup', 'internet.DeviceProtection', 'internet.TechSupport',
                  'internet.StreamingTV', 'internet.StreamingMovies', 'account.Contract', 'account.PaymentMethod']

df = pd.get_dummies(df, columns=multi_cat_cols, drop_first=True)

# Verifica tipos de datos despu√©s de la conversi√≥n
print(df.dtypes)

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# 1. Definir X e y
X = df.drop(columns=['Churn'])
y = df['Churn']

# 2. Separar en entrenamiento y prueba (80/20)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 3. Crear los modelos
modelo_lr = LogisticRegression(max_iter=1000, random_state=42)
modelo_dt = DecisionTreeClassifier(random_state=42)

# 4. Entrenar los modelos
modelo_lr.fit(X_train, y_train)
modelo_dt.fit(X_train, y_train)

# 5. Predecir en test
y_pred_lr = modelo_lr.predict(X_test)
y_pred_dt = modelo_dt.predict(X_test)

# 6. Evaluar resultados
print("Regresi√≥n Log√≠stica:")
print("Accuracy:", accuracy_score(y_test, y_pred_lr))
print(classification_report(y_test, y_pred_lr))
print("Matriz de Confusi√≥n:\n", confusion_matrix(y_test, y_pred_lr))

print("\n√Årbol de Decisi√≥n:")
print("Accuracy:", accuracy_score(y_test, y_pred_dt))
print(classification_report(y_test, y_pred_dt))
print("Matriz de Confusi√≥n:\n", confusion_matrix(y_test, y_pred_dt))

"""Interpretaci√≥n r√°pida:
Regresi√≥n Log√≠stica:

Accuracy ~80% es bueno para un problema de churn.

Mejor desempe√±o para la clase ‚Äú0‚Äù (no cancelan) que para ‚Äú1‚Äù (cancelan).

Precisi√≥n, recall y F1 para clase 1 son menores (~0.6), lo que indica que el modelo falla m√°s en detectar cancelaciones.

Matriz de confusi√≥n muestra que hay falsos negativos (176) y falsos positivos (101).

√Årbol de Decisi√≥n:

Accuracy m√°s baja (~74%).

Menor recall y precisi√≥n para clase ‚Äú1‚Äù en comparaci√≥n con regresi√≥n log√≠stica.

Modelo menos sensible a la clase minoritaria (churn).

Qu√© hacer ahora:
Balancear el dataset (SMOTE o similar) para mejorar detecci√≥n de cancelaciones (clase minoritaria).

Probar modelos m√°s robustos: Random Forest, Gradient Boosting, XGBoost, LightGBM.

Ajustar hiperpar√°metros usando GridSearchCV o RandomizedSearchCV.

Validaci√≥n cruzada para evaluar estabilidad del modelo.

Explorar variables m√°s influyentes con importancia de caracter√≠sticas.

Visualizar curvas ROC y calcular AUC para una evaluaci√≥n m√°s completa.


"""

from imblearn.over_sampling import SMOTE
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix

# 1. Crear objeto SMOTE
smote = SMOTE(random_state=42)

# 2. Aplicar SMOTE SOLO a los datos de entrenamiento
X_train_res, y_train_res = smote.fit_resample(X_train, y_train)

# 3. Verificar nueva distribuci√≥n de clases
print("Distribuci√≥n original de y_train:")
print(y_train.value_counts())
print("\nDistribuci√≥n despu√©s de SMOTE:")
print(y_train_res.value_counts())

# 4. Entrenar modelo con datos balanceados
modelo_lr = LogisticRegression(max_iter=1000)
modelo_lr.fit(X_train_res, y_train_res)

# 5. Evaluar modelo en conjunto de prueba original
y_pred = modelo_lr.predict(X_test)

print("Reporte clasificaci√≥n:")
print(classification_report(y_test, y_pred))
print("Matriz de confusi√≥n:")
print(confusion_matrix(y_test, y_pred))

"""¬°Perfecto! El SMOTE ha balanceado muy bien las clases en el entrenamiento. Algunos puntos a destacar:

La recall para la clase 1 (clientes que cancelaron) mejor√≥ bastante, de aproximadamente 0.53 a 0.74. Esto indica que ahora el modelo identifica mejor a los que cancelan.

La precisi√≥n de la clase 1 baj√≥ un poco (de ~0.66 a 0.54), lo que significa m√°s falsos positivos, pero ese trade-off es com√∫n al mejorar recall en clases minoritarias.

La exactitud global baj√≥ un poco, lo cual es t√≠pico cuando se balancea el dataset y se mejora la sensibilidad para la clase minoritaria.

En resumen, este es un buen resultado para un problema desbalanceado porque ahora el modelo es m√°s sensible a detectar clientes que cancelan, que es el objetivo principal en churn.
"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# Crear el modelo Random Forest
modelo_rf = RandomForestClassifier(random_state=42)

# Entrenar con los datos de entrenamiento balanceados
modelo_rf.fit(X_train_res, y_train_res)  # usa los datos balanceados de SMOTE

# Predecir en el conjunto de prueba
y_pred_rf = modelo_rf.predict(X_test)

# Evaluar resultados
print("Accuracy:", accuracy_score(y_test, y_pred_rf))
print(classification_report(y_test, y_pred_rf))
print("Matriz de Confusi√≥n:\n", confusion_matrix(y_test, y_pred_rf))

"""Muy bueno, el Random Forest mejora un poco el recall para la clase minoritaria (los que cancelaron), comparado con los modelos anteriores, aunque la precisi√≥n sigue siendo baja para esa clase.

Ahora, se puede:

Ajustar hiperpar√°metros del Random Forest para mejorar resultados (por ejemplo, usando GridSearchCV).

Probar otros modelos o combinaciones (XGBoost, LightGBM).

Hacer an√°lisis de importancia de variables para entender qu√© impacta m√°s la cancelaci√≥n.

Visualizar la matriz de confusi√≥n o curva ROC.
"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV

# Definir el modelo base
rf = RandomForestClassifier(random_state=42)

# Definir el espacio de hiperpar√°metros a explorar
param_grid = {
    'n_estimators': [50, 100, 200],        # cantidad de √°rboles
    'max_depth': [None, 10, 20, 30],       # profundidad m√°xima del √°rbol
    'min_samples_split': [2, 5, 10],       # min. muestras para dividir nodo
    'min_samples_leaf': [1, 2, 4],         # min. muestras en hoja
    'max_features': ['sqrt', 'log2']  # quitar 'auto'
}


# Configurar GridSearchCV
grid_search = GridSearchCV(
    estimator=rf,
    param_grid=param_grid,
    cv=3,                 # validaci√≥n cruzada 3 folds
    n_jobs=-1,            # usar todos los cores disponibles
    verbose=2,
    scoring='f1'          # optimizamos seg√∫n el F1 score, balance entre precisi√≥n y recall
)

# Ejecutar la b√∫squeda
grid_search.fit(X_train, y_train)

# Mejor combinaci√≥n de hiperpar√°metros
print("Mejores hiperpar√°metros:", grid_search.best_params_)

# Evaluar el mejor modelo en test
best_rf = grid_search.best_estimator_
y_pred = best_rf.predict(X_test)

from sklearn.metrics import classification_report, confusion_matrix

print("Reporte clasificaci√≥n:")
print(classification_report(y_test, y_pred))
print("Matriz de confusi√≥n:")
print(confusion_matrix(y_test, y_pred))

X_train = X_train.dropna()
y_train = y_train.loc[X_train.index]

print("Filas antes de dropna:", len(X_train))
X_train_clean = X_train.dropna()
print("Filas despu√©s de dropna:", len(X_train_clean))
print("Filas eliminadas:", len(X_train) - len(X_train_clean))

print("NaN en X_train:", X_train.isna().sum().sum())
print("NaN en y_train:", y_train.isna().sum())

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV

# Definir el modelo base
rf = RandomForestClassifier(random_state=42)

# Definir el espacio de hiperpar√°metros a explorar
param_grid = {
    'n_estimators': [50, 100, 200],        # cantidad de √°rboles
    'max_depth': [None, 10, 20, 30],       # profundidad m√°xima del √°rbol
    'min_samples_split': [2, 5, 10],       # min. muestras para dividir nodo
    'min_samples_leaf': [1, 2, 4],         # min. muestras en hoja
    'max_features': ['sqrt', 'log2']  # quitar 'auto'
}


# Configurar GridSearchCV
grid_search = GridSearchCV(
    estimator=rf,
    param_grid=param_grid,
    cv=3,                 # validaci√≥n cruzada 3 folds
    n_jobs=-1,            # usar todos los cores disponibles
    verbose=2,
    scoring='f1'          # optimizamos seg√∫n el F1 score, balance entre precisi√≥n y recall
)

# Ejecutar la b√∫squeda
grid_search.fit(X_train, y_train)

# Mejor combinaci√≥n de hiperpar√°metros
print("Mejores hiperpar√°metros:", grid_search.best_params_)

# Evaluar el mejor modelo en test
best_rf = grid_search.best_estimator_
y_pred = best_rf.predict(X_test)

from sklearn.metrics import classification_report, confusion_matrix

print("Reporte clasificaci√≥n:")
print(classification_report(y_test, y_pred))
print("Matriz de confusi√≥n:")
print(confusion_matrix(y_test, y_pred))

"""¬°Muy buen resultado! üéâ

Con esos hiperpar√°metros ajustados, Random Forest logr√≥:

Accuracy: 80% (lo que indica que el 80% de las predicciones fueron correctas)

Recall en clase 1 (cancelaciones): 49% (detecta cerca de la mitad de los clientes que realmente cancelaron)

Precisi√≥n en clase 1: 67% (cuando predice cancelaci√≥n, acierta en un 67%)

F1-score: 0.56 para la clase 1, un balance entre precisi√≥n y recall.

Matriz de confusi√≥n muestra que todav√≠a hay un buen n√∫mero de falsos negativos (191), o sea, clientes que cancelaron pero no fueron detectados.

Exacto, justo as√≠:

Modelos que requieren normalizaci√≥n (como la Regresi√≥n Log√≠stica)

Modelos que no requieren normalizaci√≥n (como el √Årbol de Decisi√≥n y el Random Forest)

Modelos con normalizaci√≥n (p. ej. Regresi√≥n Log√≠stica)
Accuracy (Exactitud): 0.80 (80%)

Precision (Precisi√≥n) clase "churn": 0.66

Recall (Sensibilidad) clase "churn": 0.53

F1-score clase "churn": 0.59

Matriz de Confusi√≥n:

Verdaderos positivos (churn detectados correctamente): 197

Falsos negativos (churn no detectados): 176

Falsos positivos: 101

Verdaderos negativos: 935

Modelos sin normalizaci√≥n
√Årbol de Decisi√≥n
Accuracy: 0.74 (74%)

Precision clase "churn": 0.51

Recall clase "churn": 0.49

F1-score clase "churn": 0.50

Matriz de Confusi√≥n:

TP: 184

FN: 189

FP: 175

TN: 861

Random Forest (sin ajustar)
Accuracy: 0.77 (77%)

Precision clase "churn": 0.56

Recall clase "churn": 0.63

F1-score clase "churn": 0.59

Matriz de Confusi√≥n:

TP: 235

FN: 138

FP: 188

TN: 848

Random Forest (ajustado con GridSearchCV)
Accuracy: 0.80 (80%)

Precision clase "churn": 0.67

Recall clase "churn": 0.49

F1-score clase "churn": 0.56

Matriz de Confusi√≥n:

TP: 182

FN: 191

FP: 90

TN: 946

Conclusiones sobre los modelos y sus m√©tricas
Exactitud (Accuracy):

Los modelos de Regresi√≥n Log√≠stica y Random Forest ajustado tienen la mejor exactitud (~80%).

El √Årbol de Decisi√≥n queda un poco m√°s bajo (~74%).
Esto indica que en general el Random Forest ajustado y la Regresi√≥n Log√≠stica clasifican correctamente m√°s casos.

Precisi√≥n para la clase minoritaria (Churn = 1):

El Random Forest ajustado tiene la mayor precisi√≥n (0.67), lo que significa que cuando predice que un cliente va a cancelar, tiene m√°s probabilidad de estar en lo correcto (menos falsos positivos).

La Regresi√≥n Log√≠stica es segunda (0.66), bastante cercana.

Random Forest sin ajustar y √Årbol de Decisi√≥n tienen precisiones m√°s bajas.

Recall (sensibilidad) para la clase Churn:

El Random Forest sin ajustar es el que mejor detecta a los clientes que efectivamente cancelan (recall 0.63), o sea, menos falsos negativos.

El resto de los modelos tiene recall m√°s bajo, especialmente el Random Forest ajustado y Regresi√≥n Log√≠stica (alrededor de 0.49-0.53).
Esto indica que el modelo ajustado es m√°s conservador y pierde m√°s cancelaciones reales.

F1-score (balance precisi√≥n-recall):

El mejor F1-score para la clase churn lo tienen Regresi√≥n Log√≠stica y Random Forest sin ajustar (~0.59), que mantienen un buen equilibrio entre precisi√≥n y recall.

El Random Forest ajustado baja un poco en F1 (0.56), porque mejora precisi√≥n pero baja recall.

√Årbol de Decisi√≥n queda bastante atr√°s.

Matriz de confusi√≥n:

El Random Forest ajustado reduce los falsos positivos (mejor precisi√≥n).

El Random Forest sin ajustar reduce falsos negativos (mejor recall).

La Regresi√≥n Log√≠stica ofrece un balance, pero con menor recall.

¬øCu√°l es el mejor modelo?
Si quieres minimizar falsos positivos (es decir, evitar predecir churn cuando no hay churn, para no malgastar recursos):
El Random Forest ajustado es la mejor opci√≥n por su precisi√≥n m√°s alta y buena exactitud.

Si quieres maximizar la detecci√≥n de churn (recall alto), incluso a costa de m√°s falsos positivos:
El Random Forest sin ajustar es mejor, detecta m√°s cancelaciones reales.

Si buscas un equilibrio razonable sin mucho ajuste complejo:
La Regresi√≥n Log√≠stica es buena opci√≥n, con alta exactitud y balance aceptable de precisi√≥n y recall.

El √Årbol de Decisi√≥n es el que menos rendimiento mostr√≥, y no ser√≠a la opci√≥n recomendada.

En resumen:
El Random Forest ajustado gana en precisi√≥n y exactitud.

El Random Forest sin ajuste gana en recall.

La Regresi√≥n Log√≠stica es buena para balancear sin tanta complejidad.

Todo depende de si tu prioridad es detectar la mayor cantidad de cancelaciones (recall) o evitar predicciones err√≥neas (precisi√≥n).

¬øQu√© es overfitting y underfitting?
Overfitting: el modelo aprende demasiado bien los datos de entrenamiento, incluyendo ruido o detalles espec√≠ficos, y por eso tiene muy buen desempe√±o en entrenamiento pero pobre generalizaci√≥n en datos nuevos (test).

Underfitting: el modelo es muy simple y no logra captar patrones importantes, por lo que falla tanto en entrenamiento como en test.

An√°lisis para tus modelos
¬øHay se√±ales de overfitting?

Para detectar overfitting, normalmente se comparan las m√©tricas (accuracy, f1, recall, etc.) entre entrenamiento y prueba:

Si el desempe√±o en entrenamiento es mucho mejor que en test, puede ser overfitting.

En tu caso, como solo mostraste m√©tricas de test, habr√≠a que revisar el desempe√±o en entrenamiento para confirmarlo.

¬øPosible underfitting?

Si los modelos tienen baja precisi√≥n, recall y f1 tanto en entrenamiento como en test, eso podr√≠a indicar underfitting.

El √Årbol de Decisi√≥n con menor accuracy y f1 puede estar sufriendo de underfitting, porque es un modelo m√°s simple y si no est√° bien parametrizado, no aprende bien.

Random Forest sin ajustar vs. ajustado

El Random Forest sin ajuste suele tener mayor recall, pero menor precisi√≥n, lo que indica que puede estar sobreajustando un poco para detectar m√°s casos positivos, pero a costa de falsos positivos (ruido).

El ajuste (GridSearchCV) generalmente busca controlar el overfitting regulando hiperpar√°metros como profundidad y muestras m√≠nimas en hojas.

El hecho que el modelo ajustado tenga un mejor balance pero un recall menor indica que redujo cierto overfitting, haci√©ndolo m√°s generalizable, aunque sacrifica detecci√≥n.

Regresi√≥n Log√≠stica

Modelo lineal simple que suele evitar overfitting f√°cilmente.

Resultados bastante estables y balanceados, lo que sugiere bajo riesgo de overfitting ni underfitting significativo.

En resumen para tus modelos:
Modelo	Probable estado	Justificaci√≥n
Regresi√≥n Log√≠stica	Buen ajuste	M√©tricas balanceadas, sin se√±ales de sobreajuste
√Årbol de Decisi√≥n	Posible underfitting	M√©tricas bajas, modelo simple
RF sin ajuste	Ligero overfitting posible	Recall alto (detecta bien), precisi√≥n baja (muchos falsos positivos)
RF ajustado	Mejor balance, menos overfitting	M√©tricas m√°s balanceadas, menor recall, control de hiperpar√°metros
"""

# Modelos entrenados: modelo_lr, modelo_dt, rf, best_rf

print("Comparaci√≥n de desempe√±o en entrenamiento y prueba:\n")

for nombre, modelo in [
    ('Regresi√≥n Log√≠stica', modelo_lr),
    ('√Årbol de Decisi√≥n', modelo_dt),
    ('Random Forest sin ajuste', rf),
    ('Random Forest ajustado', best_rf)
]:
    acc_train = modelo.score(X_train, y_train)
    acc_test = modelo.score(X_test, y_test)
    print(f"{nombre}:")
    print(f"  Accuracy en entrenamiento: {acc_train:.4f}")
    print(f"  Accuracy en prueba:        {acc_test:.4f}")
    diferencia = acc_train - acc_test

    if diferencia > 0.1:
        print("  Posible overfitting (mejor en entrenamiento que en prueba)")
    elif diferencia < -0.05:
        print("  Posible underfitting (mejor en prueba que en entrenamiento, o ambos bajos)")
    else:
        print("  Buen ajuste (similar desempe√±o en entrenamiento y prueba)")
    print()

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report, confusion_matrix

# Definir el modelo base
rf = RandomForestClassifier(random_state=42)

# Definir el espacio de hiperpar√°metros a explorar
param_grid = {
    'n_estimators': [50, 100, 200],        # cantidad de √°rboles
    'max_depth': [None, 10, 20, 30],       # profundidad m√°xima del √°rbol
    'min_samples_split': [2, 5, 10],       # min. muestras para dividir nodo
    'min_samples_leaf': [1, 2, 4],         # min. muestras en hoja
    'max_features': ['sqrt', 'log2']       # corregido: 'auto' no es v√°lido
}

# Configurar GridSearchCV
grid_search = GridSearchCV(
    estimator=rf,
    param_grid=param_grid,
    cv=3,
    n_jobs=-1,
    verbose=2,
    scoring='f1'  # optimizamos seg√∫n f1-score
)

# Ejecutar b√∫squeda
grid_search.fit(X_train, y_train)

# Obtener mejor modelo (mejor estimador)
best_rf = grid_search.best_estimator_

# Asegurarse que el mejor modelo est√© entrenado
# (GridSearchCV ya entrena al mejor modelo, pero por seguridad:)
if not hasattr(best_rf, "estimators_"):
    best_rf.fit(X_train, y_train)

# Evaluar en conjunto de prueba
y_pred = best_rf.predict(X_test)

print("Mejores hiperpar√°metros:", grid_search.best_params_)
print("Reporte clasificaci√≥n:")
print(classification_report(y_test, y_pred))
print("Matriz de confusi√≥n:")
print(confusion_matrix(y_test, y_pred))

"""Perfecto, ese resultado te muestra que el mejor Random Forest tras la b√∫squeda con GridSearchCV tiene:

Accuracy (Exactitud) ~ 80%: El modelo acierta en el 80% de los casos.

Precision para clase 1 (cancelaci√≥n): 0.67: De todos los que predice como cancelaci√≥n, el 67% es correcto.

Recall para clase 1: 0.49: El modelo detecta el 49% de los clientes que realmente cancelaron (a√∫n queda margen para mejorar aqu√≠).

F1-score para clase 1: 0.56: Balance entre precisi√≥n y recall.

Matriz de confusi√≥n:

Verdaderos positivos (cancelaci√≥n detectada correctamente): 182

Falsos negativos (cancelaci√≥n no detectada): 191

Verdaderos negativos (no cancelaci√≥n correctamente identificada): 946

Falsos positivos (no cancelaci√≥n incorrectamente marcada como cancelaci√≥n): 90

Interpretaci√≥n:

El modelo es bueno para identificar clientes que no cancelan (clase 0), pero a√∫n tiene dificultades para captar a todos los que s√≠ cancelan (clase 1), es decir, el recall de la clase minoritaria podr√≠a mejorar.

Esto es com√∫n en datasets desbalanceados.

El ajuste de hiperpar√°metros mejor√≥ respecto al Random Forest sin ajuste, pero siempre puedes seguir intentando balancear el dataset, ajustar otros par√°metros, o probar otros modelos.

Interpretaci√≥n y Conclusiones
Importancia de Variables seg√∫n el modelo:
1. Regresi√≥n Log√≠stica (coeficientes)
Los coeficientes indican la influencia de cada variable en la probabilidad de cancelaci√≥n (Churn).

Coeficientes positivos ‚Üí aumentan la probabilidad de churn.

Coeficientes negativos ‚Üí disminuyen la probabilidad de churn.

Es √∫til identificar cu√°les caracter√≠sticas impactan m√°s la decisi√≥n del cliente de cancelar o no.

2. Random Forest (importancia de caracter√≠sticas)
Random Forest calcula la importancia de cada variable basada en cu√°nto mejora la pureza de los nodos en los √°rboles cuando se usa esa variable.

Variables con mayor importancia tienen mayor peso en la predicci√≥n del modelo.

Se puede visualizar con gr√°ficos de barras para entender qu√© factores explican mejor el churn.

Por ejemplo, podr√≠an ser variables como tenure, Monthly Charges, Contract Type, o servicios espec√≠ficos de internet.

3. Otros modelos (SVM, KNN, XGBoost)
SVM: Se interpretan los coeficientes en modelos lineales (similar a regresi√≥n log√≠stica).

KNN: No tiene coeficientes directos, pero se puede analizar la contribuci√≥n de las variables a la distancia.

XGBoost: Al igual que Random Forest, proporciona importancia de variables y permite gr√°ficos detallados.
"""

import matplotlib.pyplot as plt
import pandas as pd

# Obtener importancia de caracter√≠sticas
importancias = best_rf.feature_importances_

# Crear DataFrame para visualizaci√≥n
df_importancia = pd.DataFrame({
    'Caracter√≠stica': X_train.columns,
    'Importancia': importancias
}).sort_values(by='Importancia', ascending=False)

# Graficar
plt.figure(figsize=(10,6))
plt.barh(df_importancia['Caracter√≠stica'], df_importancia['Importancia'])
plt.gca().invert_yaxis()
plt.title("Importancia de Caracter√≠sticas - Random Forest")
plt.xlabel("Importancia")
plt.show()

import numpy as np
import pandas as pd

# Coeficientes del modelo entrenado (modelo_lr)
coeficientes = modelo_lr.coef_[0]  # si es regresi√≥n binaria

# Crear DataFrame con caracter√≠sticas y coeficientes
df_coef = pd.DataFrame({
    'Caracter√≠stica': X_train.columns,
    'Coeficiente': coeficientes
}).sort_values(by='Coeficiente', key=abs, ascending=False)

print(df_coef)

# Para ver los coeficientes positivos y negativos, que indican aumento o disminuci√≥n del riesgo de churn

import matplotlib.pyplot as plt

importancias = best_rf.feature_importances_
df_importancia = pd.DataFrame({
    'Caracter√≠stica': X_train.columns,
    'Importancia': importancias
}).sort_values(by='Importancia', ascending=False)

plt.figure(figsize=(10,6))
plt.barh(df_importancia['Caracter√≠stica'], df_importancia['Importancia'])
plt.gca().invert_yaxis()
plt.title("Importancia de Caracter√≠sticas - Random Forest")
plt.xlabel("Importancia")
plt.show()

from sklearn.svm import SVC

# Entrenar un SVM lineal
modelo_svm = SVC(kernel='linear', probability=True, random_state=42)
modelo_svm.fit(X_train, y_train)

coef_svm = modelo_svm.coef_[0]

import pandas as pd

df_coef_svm = pd.DataFrame({
    'Caracter√≠stica': X_train.columns,
    'Coeficiente': coef_svm
}).sort_values(by='Coeficiente', key=abs, ascending=False)

print(df_coef_svm)

from sklearn.svm import SVC
import pandas as pd

# 1. Crear y entrenar el modelo SVM lineal
modelo_svm = SVC(kernel='linear', probability=True, random_state=42)
modelo_svm.fit(X_train, y_train)

# 2. Obtener coeficientes (importancia) de las caracter√≠sticas
coef_svm = modelo_svm.coef_[0]

# 3. Crear DataFrame para mostrar coeficientes ordenados por importancia absoluta
df_coef_svm = pd.DataFrame({
    'Caracter√≠stica': X_train.columns,
    'Coeficiente': coef_svm
})

df_coef_svm['Importancia Absoluta'] = df_coef_svm['Coeficiente'].abs()
df_coef_svm = df_coef_svm.sort_values(by='Importancia Absoluta', ascending=False).drop(columns='Importancia Absoluta')

# 4. Mostrar resultados
print(df_coef_svm)

"""Una comparaci√≥n directa de la importancia de caracter√≠sticas entre los modelos que s√≠ la permiten ‚Äî en concreto:

Regresi√≥n Log√≠stica (coeficientes)
SVM lineal (coeficientes)
Random Forest (importancia de caracter√≠sticas basada en √°rboles)
"""

import pandas as pd

# Regresi√≥n Log√≠stica
coef_rl = modelo_rl.coef_[0]
df_coef_rl = pd.DataFrame({
    'Caracter√≠stica': X_train.columns,
    'Coef_RegLog': coef_rl
})
df_coef_rl['Importancia Abs RegLog'] = df_coef_rl['Coef_RegLog'].abs()

# SVM Lineal
coef_svm = modelo_svm.coef_[0]
df_coef_svm = pd.DataFrame({
    'Caracter√≠stica': X_train.columns,
    'Coef_SVM': coef_svm
})
df_coef_svm['Importancia Abs SVM'] = df_coef_svm['Coef_SVM'].abs()

# Random Forest (importancia de caracter√≠sticas)
importancias_rf = best_rf.feature_importances_
df_imp_rf = pd.DataFrame({
    'Caracter√≠stica': X_train.columns,
    'Imp_RandomForest': importancias_rf
})

# Unir todos en un solo DataFrame para comparar
df_comparacion = df_coef_rl[['Caracter√≠stica', 'Coef_RegLog', 'Importancia Abs RegLog']].merge(
    df_coef_svm[['Caracter√≠stica', 'Coef_SVM', 'Importancia Abs SVM']],
    on='Caracter√≠stica'
).merge(
    df_imp_rf,
    on='Caracter√≠stica'
)

# Ordenar por importancia absoluta en Random Forest (puedes cambiar la columna para ordenar seg√∫n otro criterio)
df_comparacion = df_comparacion.sort_values(by='Imp_RandomForest', ascending=False).reset_index(drop=True)

# Mostrar tabla comparativa
print(df_comparacion)

from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression

# Crear pipeline
modelo_rl = Pipeline([
    ('scaler', StandardScaler()),
    ('logisticregression', LogisticRegression())
])

# Entrenar
modelo_rl.fit(X_train, y_train)

from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

# Supongamos que tienes X, y
# X: DataFrame o array de features
# y: vector objetivo (clases)

# Dividir datos
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Crear pipeline con escalador y modelo
pipeline = Pipeline([
    ('scaler', StandardScaler()),          # Escalar datos
    ('logreg', LogisticRegression())       # Modelo
])

# Entrenar
pipeline.fit(X_train, y_train)

# Predecir
y_pred = pipeline.predict(X_test)

# Reporte de clasificaci√≥n
print(classification_report(y_test, y_pred))

# Para obtener coeficientes (del modelo dentro del pipeline)
coeficientes = pipeline.named_steps['logreg'].coef_[0]

# Mostrar coeficientes con nombres de columnas si X es DataFrame
for feature, coef in zip(X.columns, coeficientes):
    print(f"{feature}: {coef:.4f}")

"""Interpretaci√≥n y conclusiones:

Estos coeficientes y m√©tricas nos permiten sacar conclusiones claves:

Interpretaci√≥n de m√©tricas de evaluaci√≥n (Logistic Regression)
Accuracy ~ 81%: buen porcentaje de aciertos globales.

Precisi√≥n y Recall para clase 1 (churn=1) son m√°s bajos (0.67 y 0.54), indica que el modelo detecta s√≥lo algo m√°s de la mitad de los casos reales de cancelaci√≥n, y que el 33% de las predicciones positivas son falsas alarmas.

El F1-score para clase 1 es 0.59, balanceando precisi√≥n y recall.

Interpretaci√≥n de coeficientes
Coeficientes positivos indican aumento de probabilidad de churn (clase 1).

Coeficientes negativos indican reducci√≥n de probabilidad de churn.

Ejemplos de variables con impacto relevante:
Variable	Coeficiente	Interpretaci√≥n
customer.tenure	-1.3954	M√°s tiempo como cliente reduce churn.
account.Charges.Total	0.6522	M√°s cargos totales aumentan churn.
internet.InternetService_Fiber optic	0.6029	Tener fibra √≥ptica aumenta churn.
account.Contract_Two year	-0.6505	Contrato a 2 a√±os reduce churn.
account.Contract_One year	-0.2929	Contrato a 1 a√±o tambi√©n reduce churn.
account.PaperlessBilling	0.1442	Facturaci√≥n sin papel aumenta churn.
"""

Conclusiones r√°pidas:

Clientes con contratos m√°s largos tienden a quedarse (coef negativos grandes).

Clientes con fibra √≥ptica y mayores cargos tienden a irse.

Tiempo como cliente es el factor con mayor influencia protectora (coef muy negativo).

Algunas variables binarias relacionadas a servicios espec√≠ficos (ej. streaming, soporte) tienen coeficientes menores pero con sentido.

import pandas as pd
import matplotlib.pyplot as plt

# Asumiendo que 'best_rf' es tu Random Forest ya entrenado (el mejor modelo tras GridSearchCV)

# Obtener importancia de caracter√≠sticas
importancias = best_rf.feature_importances_

# Crear DataFrame para mejor visualizaci√≥n
df_importancias = pd.DataFrame({
    'Caracter√≠stica': X_train.columns,
    'Importancia': importancias
})

# Ordenar por importancia descendente
df_importancias = df_importancias.sort_values(by='Importancia', ascending=False)

# Mostrar las 10 caracter√≠sticas m√°s importantes
print(df_importancias.head(10))

# Gr√°fico de barras
plt.figure(figsize=(10,6))
plt.barh(df_importancias['Caracter√≠stica'].head(10)[::-1], df_importancias['Importancia'].head(10)[::-1])
plt.xlabel('Importancia')
plt.title('Top 10 Caracter√≠sticas seg√∫n Random Forest')
plt.show()

"""Resultados de importancia de variables para el modelo Random Forest.

Interpretaci√≥n r√°pida:

customer.tenure (Tiempo con la empresa) es la variable m√°s importante, lo que indica que cu√°nto tiempo un cliente lleva con la empresa es un factor clave para predecir la cancelaci√≥n (churn).

account.Charges.Total y account.Charges.Monthly tambi√©n son muy relevantes, lo que tiene sentido porque cu√°nto paga el cliente influye en su probabilidad de quedarse o irse.

Cuentas_Diarias (quiz√°s uso o cantidad de cuentas diarias) tiene un peso significativo.

Variables relacionadas con servicios de internet (como fibra √≥ptica) y contratos anuales (account.Contract_Two year) tambi√©n influyen notablemente.

Los m√©todos de pago y algunos servicios adicionales (como soporte t√©cnico) tienen importancia menor pero relevante.
"""

import pandas as pd
import numpy as np

# Suponiendo que tu modelo SVM lineal est√° entrenado y se llama modelo_svm
# Y que X_train es tu DataFrame con columnas originales

coef_svm = modelo_svm.coef_[0]  # Coeficientes del modelo para la primera clase (binario)

df_coef_svm = pd.DataFrame({
    'Caracter√≠stica': X_train.columns,
    'Coeficiente': coef_svm
})

# Ordenar por valor absoluto para ver los m√°s influyentes
df_coef_svm['Importancia_abs'] = df_coef_svm['Coeficiente'].abs()
df_coef_svm = df_coef_svm.sort_values(by='Importancia_abs', ascending=False).drop(columns='Importancia_abs')

print(df_coef_svm)

"""La importancia de variables para el modelo SVM lineal.

Para resumir y comparar con los otros modelos:

Variables con coeficientes grandes (en valor absoluto) como customer.tenure, internet.InternetService_Fiber optic y account.Charges.Total son las m√°s influyentes para predecir churn.

Coeficientes negativos indican que esas variables reducen la probabilidad de churn.

Coeficientes positivos aumentan la probabilidad.
"""

pip install shap

import shap
import numpy as np
import pandas as pd
from sklearn.neighbors import KNeighborsClassifier

# Asumiendo que ya tienes X_train, y_train, X_test, y_test y el modelo entrenado (knn_model)

# Ejemplo: entrenar KNN si no lo tienes a√∫n
knn_model = KNeighborsClassifier(n_neighbors=5)
knn_model.fit(X_train, y_train)

# Crear el explicador KernelExplainer para modelos que no son √°rboles ni lineales
explainer = shap.KernelExplainer(knn_model.predict_proba, shap.sample(X_train, 100))

# Elegimos algunas muestras de prueba para explicar
X_sample = shap.sample(X_test, 10)

# Calculamos los valores SHAP
shap_values = explainer.shap_values(X_sample)

# Visualizaci√≥n resumen para la clase 1 (por ejemplo, "Churn")
shap.summary_plot(shap_values[1], X_sample, feature_names=X_train.columns)

import shap
import numpy as np
import pandas as pd
from sklearn.neighbors import KNeighborsClassifier

# Entrena el modelo KNN si no lo tienes
knn_model = KNeighborsClassifier(n_neighbors=5)
knn_model.fit(X_train, y_train)

# Crear el explicador KernelExplainer
explainer = shap.KernelExplainer(knn_model.predict_proba, shap.sample(X_train, 100))

# Selecciona una muestra peque√±a para explicar
X_sample = shap.sample(X_test, 10)

# Calcular valores SHAP (devuelve lista de arrays, uno por clase)
shap_values = explainer.shap_values(X_sample)

# shap_values es una lista con un array por clase; por ejemplo para clase 1:
shap_class1 = shap_values[1]

# Verifica las dimensiones
print("X_sample shape:", X_sample.shape)
print("shap_class1 shape:", shap_class1.shape)

# Para KernelExplainer a veces es necesario pasar los datos como numpy array:
shap.summary_plot(shap_class1, X_sample.values, feature_names=X_train.columns)

"""Perfecto, el error queda claro con las shapes:

X_sample tiene shape (10, 31) ‚Üí 10 instancias, 31 features.

shap_class1 tiene shape (31, 2) ‚Üí esto no corresponde.

Eso indica que shap_values[1] no es un array de shap values para las instancias, sino que probablemente sea algo diferente o transpuesto.

Cuando usas KernelExplainer con un modelo multi-clase, explainer.shap_values(X) devuelve una lista con un array para cada clase, donde cada array es shape (num_samples, num_features).

Aqu√≠ parece que los tienes invertidos o mal asignados.
"""

print(type(shap_values))       # deber√≠a ser list
print(len(shap_values))        # n√∫mero de clases (por ejemplo 2)
print(shap_values[0].shape)    # shape del array para clase 0
print(shap_values[1].shape)    # shape del array para clase 1

shap_values = explainer.shap_values(X_sample)
print(type(shap_values))  # deber√≠a ser list (si multiclass) o ndarray (si binario)
print(len(shap_values))   # si multiclass, n√∫mero de clases
print(shap_values[0].shape)  # (10, 31) por ejemplo para clase 0
print(shap_values[1].shape)  # (10, 31) para clase 1

shap.summary_plot(shap_values[1], X_sample, feature_names=X_train.columns)

print("Shape de shap_values[1]:", shap_values[1].shape)
print("Shape de X_sample:", X_sample.shape)
print("Columnas X_sample:", X_sample.columns)
print("Columnas X_train:", X_train.columns)

# Supongamos que ya tienes definido el explainer (TreeExplainer para RandomForest o KernelExplainer)
# Aseg√∫rate que explainer est√© definido para el modelo entrenado

# Calcular shap_values para X_sample (las 10 muestras que quieres analizar)
shap_values = explainer.shap_values(X_sample)

# Verifica la forma para clase 1
print("Shape shap_values[1]:", shap_values[1].shape)  # Debe ser (10, 31)

# Ahora puedes graficar sin error:
shap.summary_plot(shap_values[1], X_sample, feature_names=X_sample.columns)

shap_values = explainer.shap_values(X_sample)  # sin .T
print(shap_values[1].shape)  # debe salir (10, 31)

shap.summary_plot(shap_values[1], X_sample, feature_names=X_sample.columns)

print("X_sample shape:", X_sample.shape)

shap_values = explainer.shap_values(X_sample)  # NO usar X_sample.T
print("shap_values[1] shape:", shap_values[1].shape)

import shap
from sklearn.neighbors import KNeighborsClassifier

# Suponiendo que ya tienes:
# X_train, y_train, X_test, y_test
# Entrenamos el modelo KNN
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)

# Creamos el explainer para KNN (KernelExplainer funciona para cualquier modelo)
explainer = shap.KernelExplainer(knn.predict_proba, shap.sample(X_train, 100))

# Calculamos los valores SHAP para un subconjunto de datos
X_sample = shap.sample(X_test, 10)  # ejemplo con 10 muestras para visualizaci√≥n
shap_values = explainer.shap_values(X_sample)

# Visualizamos el resumen de SHAP para la clase 1 (por ejemplo, Churn = 1)
shap.summary_plot(shap_values[1], X_sample, feature_names=X_train.columns)

print(f"X_sample shape: {X_sample.shape}")
print(f"shap_values[0] shape: {shap_values[0].shape}")
print(f"shap_values[1] shape: {shap_values[1].shape}")

print(type(shap_values))
print(len(shap_values))
print(shap_values[0].shape)
print(shap_values[1].shape)

import shap

# Explicador con KernelExplainer (ejemplo, con funci√≥n predict_proba)
explainer = shap.KernelExplainer(modelo_knn.predict_proba, shap.sample(X_train, 100))

# Calcula valores SHAP para X_sample (10 filas)
shap_values = explainer.shap_values(X_sample)

print(type(shap_values))  # deber√≠a ser list o ndarray
print(len(shap_values))   # 2 para clasificaci√≥n binaria
print(shap_values[0].shape)  # (10, 31)
print(shap_values[1].shape)  # (10, 31)

# Ahora s√≠ puedes graficar sin problema:
shap.summary_plot(shap_values[1], X_sample)

from sklearn.neighbors import KNeighborsClassifier

# Entrenar modelo KNN (ejemplo)
modelo_knn = KNeighborsClassifier(n_neighbors=5)
modelo_knn.fit(X_train, y_train)

import shap

# Selecciona una muestra representativa para KernelExplainer (por ejemplo 100 filas de entrenamiento)
X_train_sample = shap.sample(X_train, 100, random_state=42)

# Crear explicador con la funci√≥n predict_proba del modelo KNN
explainer = shap.KernelExplainer(modelo_knn.predict_proba, X_train_sample)

# Seleccionar algunos ejemplos para explicar (por ejemplo 10 filas del test)
X_sample = X_test.sample(10, random_state=42)

# Calcular valores SHAP para la clase positiva (Churn=1)
shap_values = explainer.shap_values(X_sample)

# Graficar resumen (beeswarm) para la clase 1
shap.summary_plot(shap_values[1], X_sample)

shap_values = explainer.shap_values(X_sample)

print("X_sample shape:", X_sample.shape)  # debe ser (10, n√∫mero de caracter√≠sticas)
print("shap_values[1] shape:", shap_values[1].shape)  # debe ser (10, n√∫mero de caracter√≠sticas)

import shap
import numpy as np

# Background sample (por ejemplo 100 muestras)
background = shap.sample(X_train, 100)

explainer = shap.KernelExplainer(modelo_knn.predict_proba, background)

# Calcula shap values para X_sample
shap_values = explainer.shap_values(X_sample)

print("X_sample shape:", X_sample.shape)
print("shap_values[1] shape:", shap_values[1].shape)  # Esto debe ser (10, 31)

def model_predict_proba_pos(X):
    return modelo_knn.predict_proba(X)[:, 1]  # Probabilidad clase 1

explainer = shap.KernelExplainer(model_predict_proba_pos, shap.sample(X_train, 100))

shap_values = explainer.shap_values(X_sample)  # Esto debe devolver un array (10, 31)

print("shap_values shape:", shap_values.shape)  # Debe ser (10, 31)

shap.summary_plot(shap_values, X_sample)

"""El gr√°fico es un summary plot de SHAP, que muestra el impacto de cada variable en las predicciones del modelo (en este caso, del KNN con Kernel SHAP).

C√≥mo interpretar este gr√°fico SHAP:
Cada punto representa una observaci√≥n (una fila de datos).

El eje horizontal muestra el valor SHAP (contribuci√≥n a la predicci√≥n): a la derecha aumenta la probabilidad de la clase positiva, a la izquierda la disminuye.

El color indica el valor de la caracter√≠stica (rojo alto, azul bajo).

Las caracter√≠sticas est√°n ordenadas de arriba hacia abajo seg√∫n su importancia media (promedio del valor absoluto SHAP).

Por ejemplo:

internet.InternetService_Fiber optic tiene un alto impacto positivo cuando es alto (puntos rojos a la derecha).

customer.tenure tiene valores altos que generalmente disminuyen la probabilidad (puntos rojos a la izquierda).

Otras variables como account.Contract_One year o account.PaymentMethod_Electronic check tambi√©n contribuyen.

Este gr√°fico es un resumen t√≠pico de valores SHAP (SHapley Additive exPlanations), que muestra la importancia y el impacto de distintas caracter√≠sticas (features) en la predicci√≥n de un modelo de machine learning.

Aqu√≠ te dejo una interpretaci√≥n general y algunas conclusiones que se pueden sacar del gr√°fico:

Eje Y: Enumera las caracter√≠sticas del modelo (por ejemplo, tipo de servicio de internet, duraci√≥n del cliente, m√©todo de pago, etc.).

Eje X: Muestra el valor SHAP, que representa el impacto que tiene cada caracter√≠stica en la predicci√≥n del modelo para una observaci√≥n individual. Valores positivos indican que la caracter√≠stica aumenta la probabilidad de un resultado (por ejemplo, que el cliente se quede o no se quede), y valores negativos indican lo contrario.

Colores: Indican el valor de la caracter√≠stica en s√≠ misma (Feature value). Azul representa valores bajos y rojo valores altos de la caracter√≠stica.

Conclusiones del gr√°fico:
internet.InternetService_Fiber optic: Esta caracter√≠stica tiene un gran impacto en la predicci√≥n. Valores altos (puntos rojos) tienden a aumentar la predicci√≥n (valor SHAP positivo), mientras que valores bajos (azul) tienden a disminuirla.

customer.tenure (antig√ºedad del cliente): Generalmente, a mayor tiempo con la empresa (rojo), mayor el impacto positivo en la predicci√≥n, sugiriendo que clientes con m√°s antig√ºedad tienden a un resultado espec√≠fico (probablemente que se queden).

account.Contract_One year: Tener un contrato de un a√±o afecta la predicci√≥n de forma negativa o positiva dependiendo del caso, pero se observa un impacto relevante.

account.PaymentMethod_Electronic check: Este m√©todo de pago parece influir negativamente en la predicci√≥n (los puntos rojos est√°n m√°s hacia valores negativos).

Otras caracter√≠sticas como internet.OnlineSecurity_Yes y account.PaperlessBilling tienen impactos variados pero menos fuertes.

En resumen:
Las caracter√≠sticas relacionadas con el tipo de servicio de internet (especialmente fibra √≥ptica), la antig√ºedad del cliente, el tipo de contrato y el m√©todo de pago son las que m√°s impactan la predicci√≥n del modelo.

Valores altos o bajos de estas caracter√≠sticas pueden aumentar o disminuir la probabilidad del resultado modelado (como la permanencia o abandono de un cliente).

El gr√°fico ayuda a entender qu√© factores son m√°s influyentes y c√≥mo los valores espec√≠ficos de cada factor afectan el resultado.

Este gr√°fico es un resumen t√≠pico de valores SHAP (SHapley Additive exPlanations), que muestra la importancia y el impacto de distintas caracter√≠sticas (features) en la predicci√≥n de un modelo de machine learning.

Aqu√≠ te dejo una interpretaci√≥n general y algunas conclusiones que se pueden sacar del gr√°fico:

Eje Y: Enumera las caracter√≠sticas del modelo (por ejemplo, tipo de servicio de internet, duraci√≥n del cliente, m√©todo de pago, etc.).

Eje X: Muestra el valor SHAP, que representa el impacto que tiene cada caracter√≠stica en la predicci√≥n del modelo para una observaci√≥n individual. Valores positivos indican que la caracter√≠stica aumenta la probabilidad de un resultado (por ejemplo, que el cliente se quede o no se quede), y valores negativos indican lo contrario.

Colores: Indican el valor de la caracter√≠stica en s√≠ misma (Feature value). Azul representa valores bajos y rojo valores altos de la caracter√≠stica.

Conclusiones del gr√°fico:
internet.InternetService_Fiber optic: Esta caracter√≠stica tiene un gran impacto en la predicci√≥n. Valores altos (puntos rojos) tienden a aumentar la predicci√≥n (valor SHAP positivo), mientras que valores bajos (azul) tienden a disminuirla.

customer.tenure (antig√ºedad del cliente): Generalmente, a mayor tiempo con la empresa (rojo), mayor el impacto positivo en la predicci√≥n, sugiriendo que clientes con m√°s antig√ºedad tienden a un resultado espec√≠fico (probablemente que se queden).

account.Contract_One year: Tener un contrato de un a√±o afecta la predicci√≥n de forma negativa o positiva dependiendo del caso, pero se observa un impacto relevante.

account.PaymentMethod_Electronic check: Este m√©todo de pago parece influir negativamente en la predicci√≥n (los puntos rojos est√°n m√°s hacia valores negativos).

Otras caracter√≠sticas como internet.OnlineSecurity_Yes y account.PaperlessBilling tienen impactos variados pero menos fuertes.

En resumen:
Las caracter√≠sticas relacionadas con el tipo de servicio de internet (especialmente fibra √≥ptica), la antig√ºedad del cliente, el tipo de contrato y el m√©todo de pago son las que m√°s impactan la predicci√≥n del modelo.

Valores altos o bajos de estas caracter√≠sticas pueden aumentar o disminuir la probabilidad del resultado modelado (como la permanencia o abandono de un cliente).

El gr√°fico ayuda a entender qu√© factores son m√°s influyentes y c√≥mo los valores espec√≠ficos de cada factor afectan el resultado.

Si quieres, puedo ayudarte a interpretar el contexto espec√≠fico si me dices qu√© predice este modelo. ¬øEs por ejemplo la probabilidad de que un cliente cancele el servicio?








ChatGPT Plus
Ese gr√°fico es un resumen de valores SHAP, que muestran qu√© tan importantes son las variables para el modelo y si empujan la predicci√≥n hacia arriba o hacia abajo.

Eje Y: lista las variables (servicio de internet, antig√ºedad, tipo de contrato, m√©todo de pago, etc.).

Eje X: valor SHAP ‚Üí impacto de esa variable en la predicci√≥n; a la derecha sube la probabilidad del resultado, a la izquierda la baja.

Color: indica si el valor de la variable es alto (rojo) o bajo (azul).

Lo que se ve:

InternetService_Fiber optic es muy influyente: tener fibra (rojo) suele empujar la predicci√≥n en una direcci√≥n, no tenerla (azul) en la opuesta.

Tenure (antig√ºedad) alto (rojo) tiende a empujar hacia un resultado y bajo (azul) hacia otro.

Contract_One year y Contract_Two year tambi√©n afectan bastante: contratos m√°s largos tienden a un efecto distinto a los cortos.

PaymentMethod_Electronic check en valores altos parece asociarse con un impacto negativo.

Variables como seguridad online, facturaci√≥n electr√≥nica o si tiene pareja influyen pero menos.

En s√≠ntesis: el modelo se apoya mucho en el tipo de servicio de internet, la antig√ºedad del cliente, el tipo de contrato y el m√©todo de pago para tomar su decisi√≥n.

Conclusiones finales: Factores m√°s influyentes en la cancelaci√≥n
InternetService_Fiber optic

Los clientes con fibra √≥ptica (puntos rojos) muestran un fuerte impacto positivo en la probabilidad de cancelaci√≥n.

Posible causa: precios m√°s altos, problemas de servicio o expectativas no cumplidas.

Customer.tenure (antig√ºedad)

Clientes nuevos (tenure bajo, azul) tienen mayor riesgo de cancelar; los antiguos (rojo) tienden a quedarse.

Esto indica que el primer periodo del contrato es cr√≠tico para fidelizar.

PaymentMethod_Electronic check

Quienes pagan con cheque electr√≥nico muestran mayor tendencia a cancelar.

Podr√≠a asociarse a menor fidelidad, problemas con el medio de pago o clientes menos vinculados digitalmente.

Contract_One year

Contratos cortos muestran mayor asociaci√≥n con cancelaci√≥n; contratos m√°s largos amortiguan el riesgo.

OnlineSecurity, OnlineBackup y TechSupport (en ‚ÄúYes‚Äù)

Los clientes que cuentan con estos servicios tienden a cancelar menos, sugiriendo que servicios de valor agregado ayudan a retener.

Propuestas para reducir cancelaciones
Ofertas y retenci√≥n proactiva para clientes con fibra √≥ptica

Revisar estructura de precios y calidad del servicio.

Programas de seguimiento post-venta para detectar problemas tempranos.

Programa de fidelizaci√≥n para clientes nuevos

Contacto directo durante los primeros 3‚Äì6 meses.

Bonos o descuentos por permanencia inicial.

Migrar clientes con pago por cheque electr√≥nico a medios m√°s estables

Incentivos para pasarse a pago autom√°tico o tarjeta (descuentos o puntos extra).

Fomentar contratos m√°s largos

Promociones que premien el compromiso de 2 a√±os.

Ofertas de paquetes con descuentos acumulativos.

Incrementar servicios complementarios de valor

Incluir seguridad online b√°sica gratis el primer a√±o.

Promocionar almacenamiento en la nube y soporte t√©cnico como beneficios diferenciales.
"""